{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5361d27b-4610-46ee-a67c-45b0aeae52d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA  \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import QuantileRegressor  \n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.stats import binomtest\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset,TensorDataset\n",
    "from collections import Counter\n",
    "from arch import arch_model\n",
    "from bayes_opt import BayesianOptimization\n",
    "from quantile_forest import RandomForestQuantileRegressor\n",
    "import yfinance as yf\n",
    "import os  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e33365-71e3-4370-ade5-cce4df2b727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标普500的 Yahoo 代码是 ^GSPC\n",
    "sp500 = yf.Ticker(\"^GSPC\")\n",
    "\n",
    "# 获取历史数据（调整时间范围）\n",
    "data = sp500.history(\n",
    "    start=\"2018-01-01\", \n",
    "    end=\"2024-12-31\", \n",
    "    interval=\"1d\"  # 可选：1d（日线）、1h（小时级）、1m（分钟级）\n",
    ")\n",
    "print(data)\n",
    "print(data.shape)\n",
    "save_dir = \"D:\\\\Desktop\\\\学习\\\\LSTM+QRF（SP500)\"\n",
    "os.makedirs(save_dir, exist_ok=True)  # 自动创建目录\n",
    "\n",
    "# ========== 保存为CSV ==========\n",
    "csv_path = os.path.join(save_dir, \"sp500_history.csv\")\n",
    "data.to_csv(csv_path, index=True)  # 保留日期索引\n",
    "print(f\"\\nCSV文件已保存至: {os.path.abspath(csv_path)}\")\n",
    "dfx = data[['Open', 'High','Low','Volume']]\n",
    "y1=data[['Close']]\n",
    "y_log = np.log(y1 / y1.shift(1))\n",
    "y = y_log.dropna()\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# ========== 生成对数收益率图表 ==========\n",
    "plt.figure(figsize=(14, 7))  # 设置画布尺寸（16:9比例）\n",
    "\n",
    "# 绘制对数收益率曲线（蓝色实线）\n",
    "plt.plot(y.index, y['Close'], \n",
    "         color='#1f77b4',  # 标准蓝色\n",
    "         linewidth=1.5, \n",
    "         label='Daily Log Returns')\n",
    "\n",
    "# 添加零基准线（红色虚线）\n",
    "plt.axhline(0, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "# 图表装饰参数\n",
    "plt.title('S&P 500 Log Returns (2018-2024)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Log Return', fontsize=12)\n",
    "plt.grid(True, linestyle=':', alpha=0.6)  # 网格线增强可读性\n",
    "plt.legend()\n",
    "\n",
    "# ========== 保存图表文件 ==========\n",
    "plot_path = os.path.join(save_dir, \"D:\\\\Desktop\\\\学术\\\\sp500_log_returns.png\")\n",
    "plt.savefig(\n",
    "    plot_path,\n",
    "    dpi=300,                # 印刷级分辨率\n",
    "    bbox_inches='tight',    # 自动裁剪空白边缘\n",
    "    facecolor='white'       # 背景色设为纯白\n",
    ")\n",
    "\n",
    "# 显示图表（保存后再调用show()）\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c088ef8e-e094-4d4e-b4d7-ab70955f1c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = arch_model(y, vol='Garch', p=1, q=1)\n",
    "results = model.fit()\n",
    "\n",
    "# 6. 获取波动率（conditional volatility）\n",
    "volatility = results.conditional_volatility\n",
    "\n",
    "# 7. 可视化波动率\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(volatility)\n",
    "plt.title(f\" (GARCH(1, 1))\")\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volatility')\n",
    "plt.savefig('D:\\\\Desktop\\\\学术\\\\garch_volatility.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 8. 输出模型的详细估计结果\n",
    "print(results.summary())\n",
    "print(volatility)\n",
    "# 直接转换 volatility 为 DataFrame，保留索引\n",
    "volatility_col = volatility.to_frame(name='volatility')\n",
    "dfx1=dfx[1:]\n",
    "volatility_col = pd.DataFrame(volatility_col, columns=['volatility'])\n",
    "# 检查转换后的形状和列名\n",
    "print(volatility_col.shape)  # 应为 (3644, 1)\n",
    "print(volatility_col.columns)  # 应包含列名 'volatility'\n",
    "print(\"dfx1 shape:\", dfx1.shape)        # 预期输出 (3645, N)\n",
    "print(\"volatility_col shape:\", volatility_col.shape)  # 预期输出 (3644, 1)\n",
    "x = pd.merge(dfx1, volatility_col, left_index=True, right_index=True, how='inner').to_numpy()\n",
    "y=y.to_numpy()\n",
    "print(x)\n",
    "scaler_x = MinMaxScaler(feature_range=(0,1)) \n",
    "scaler_y = MinMaxScaler(feature_range=(0,1))  \n",
    "\n",
    "# 归一化处理（保持与训练集参数一致）\n",
    "xsc = scaler_x.fit_transform(x)     \n",
    "ysc = scaler_y.fit_transform(y.reshape(-1,1)) \n",
    "def create_dataset(data, labels, time_steps):\n",
    "    x, y = [], []\n",
    "    for i in range(time_steps, len(data)):\n",
    "        x.append(data[i-time_steps:i])\n",
    "        y.append(labels[i, 0])  # 假设标签在第0列\n",
    "    return np.array(x), np.array(y)\n",
    "time_stamp = 30  \n",
    "x_rolling, y_rolling = create_dataset(xsc, ysc, time_stamp)\n",
    "n_samples = x_rolling.shape[0]\n",
    "split_train = int(0.8* n_samples)  \n",
    "split_test = int(0.9 * n_samples)  \n",
    "# 分割数据集（新增xpred/ypred）\n",
    "x_train1, x_test1, x_pred1 = x_rolling[:split_train], x_rolling[split_train:split_test], x_rolling[split_test:]  \n",
    "y_train1, y_test1, y_pred1 = y_rolling[:split_train], y_rolling[split_train:split_test], y_rolling[split_test:]\n",
    "# 输出形状\n",
    "print(\"训练集形状:\", x_train1.shape, y_train1.shape)\n",
    "print(\"测试集形状:\", x_test1.shape, y_test1.shape)\n",
    "print(\"预测集形状:\", x_pred1.shape, y_pred1.shape)  \n",
    "\n",
    "def quantile_loss_factory(q):\n",
    "    def loss(y_true, y_pred):\n",
    "        errors = y_true - y_pred\n",
    "        return tf.reduce_mean(tf.maximum(q * errors, (q - 1) * errors))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a149ce7-22bc-4b60-b70a-b88253e91fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 定义LSTM模型\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hs=50, num_layers=1, output_size=1, sequence_length=None, dropout=0.0):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hs = int(hs)\n",
    "        self.num_layers =int(num_layers)\n",
    "        self.input_size = input_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.lstm = nn.LSTM(input_size, hs, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hs, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)  # 动态计算batch_size\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hs).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hs).to(x.device)\n",
    "        \n",
    "        # LSTM的输出\n",
    "        output, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        \n",
    "        # 取最后一个时间步的隐藏状态\n",
    "        last_hidden_state = output[:, -1, :]  # 取最后一个时间步的隐藏状态\n",
    "        out = self.fc(last_hidden_state)\n",
    "        return out\n",
    "\n",
    "# 随机森林图计算\n",
    "def rf_graph(x):   \n",
    "    G = np.zeros((len(x), len(x))) \n",
    "    for i in range(len(x)):      \n",
    "        G[i, np.where(x == x[i])[0]] = 1\n",
    "    nodes = Counter(x)\n",
    "    nodes_num = np.array([nodes[i] for i in x])       \n",
    "    return G, G / nodes_num.reshape(-1, 1)   \n",
    "\n",
    "# 获取随机森林的权重（通过叶节点）\n",
    "def get_rfweight3(rf, x): \n",
    "    n = x.shape[0]\n",
    "    leaf = rf.apply(x)\n",
    "    ntrees = leaf.shape[1]\n",
    "    G_unnorm = np.zeros((n, n))\n",
    "    G_norm = np.zeros((n, n))  \n",
    "    for i in range(ntrees):     \n",
    "        tmp1, tmp2 = rf_graph(leaf[:, i])\n",
    "        G_unnorm += tmp1\n",
    "        G_norm += tmp2    \n",
    "    return G_unnorm / ntrees, G_norm / ntrees\n",
    "\n",
    "# 定义RWN3模型\n",
    "class RWN3():\n",
    "    def __init__(self, num_layers, dropout, hs, device='cuda', quantile=0.05):\n",
    "        self.hs = int(hs)\n",
    "        self.device = device\n",
    "        self.quantile = quantile\n",
    "        self.dropout = float(dropout)\n",
    "        self.num_layers = int(num_layers)\n",
    "\n",
    "    def fit(self, x, y, weight,tau,bs,lr,tol, n_iter,d=False,  verbose=True):\n",
    "        x = torch.FloatTensor(x)\n",
    "        y = torch.FloatTensor(y)\n",
    "        weight = torch.FloatTensor(weight)\n",
    "        lr=float(lr)\n",
    "        tau=float(tau)\n",
    "        bs=int(bs)\n",
    "        tol=float(tol)\n",
    "        n_iter=int(n_iter)\n",
    "        q = 1 - self.quantile\n",
    "        n = x.shape[0]  # 获取样本的总数\n",
    "        p = x.shape[2]  # 获取特征数，x.shape[2] 代表每个时间步的特征数\n",
    "\n",
    "        self.fnet = LSTMModel(input_size=p, hs=self.hs, num_layers=self.num_layers, output_size=1, dropout=self.dropout).to(self.device)\n",
    "        optimizer = torch.optim.Adam([{'params': self.fnet.parameters()}], lr=lr)\n",
    "\n",
    "        # 量化回归损失函数\n",
    "        def quantile_loss(y_pred, y_true, q):\n",
    "            errors = y_true - y_pred.detach()\n",
    "            max_errors = torch.max(q * errors, (q - 1) * errors)\n",
    "            return max_errors\n",
    "\n",
    "        self.loss_count = []\n",
    "        last_loss = np.inf\n",
    "        flag = 0\n",
    "        for i_iter in range(n_iter):\n",
    "            # 确保采样时不超出数据大小\n",
    "            csample = np.random.choice(n, bs, replace=False)  # 使用np.random.choice来采样，避免超出索引范围\n",
    "            tmp_x = x[csample].to(self.device)\n",
    "            tmp_y = y[csample].to(self.device)\n",
    "            tmp_w = weight[csample].reshape(bs, -1).T.to(self.device)\n",
    "\n",
    "            # 确保tmp_x的形状为 (batch_size, sequence_length, input_size)\n",
    "            tmp_x = tmp_x.view(bs, -1, p)  # Reshape为 (bs, sequence_length, input_size)\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "            # 处理 tau != None 时的操作\n",
    "            if tau is not None:   \n",
    "                if tmp_w.shape[0] != tmp_w.shape[1]:\n",
    "                    tmp_w = tmp_w.reshape(bs, -1)\n",
    "\n",
    "                # 获取 tmp_w 的对角线并调整为与样本维度匹配的形状\n",
    "                tmp_w_diag = torch.diagonal(tmp_w, dim1=-2, dim2=-1)  # 获取每个样本的对角线元素\n",
    "                tmp_w_diag = tmp_w_diag.unsqueeze(1).expand_as(tmp_w)  # 扩展为 (837, 50)\n",
    "                tmp_w = tmp_w - tmp_w_diag \n",
    "\n",
    "            tmp_fx = self.fnet(tmp_x)\n",
    "            tmp_my = torch.tile(tmp_y, (bs, 1))\n",
    "            tmp_mfx = torch.tile(tmp_fx, (1, bs))\n",
    "\n",
    "            if tau is None:       \n",
    "                loss = quantile_loss(tmp_y, tmp_fx.ravel(), q).mean()      \n",
    "            else:     \n",
    "                loss1 = quantile_loss(tmp_y, tmp_fx.ravel(), q).mean()\n",
    "                loss2 = torch.mean(quantile_loss(tmp_y, tmp_fx.ravel(), q) * tmp_w.T) * n / (n - 1)\n",
    "                loss = tau * loss1 + (1 - tau) * loss2\n",
    "\n",
    "            self.loss_count.append(loss.data.cpu().tolist())\n",
    "\n",
    "            if (np.abs(last_loss - loss.data.cpu().numpy()) <= tol) & (i_iter >= 100):\n",
    "                if verbose:\n",
    "                    print(f'Algorithm converges for RWN model at iter {i_iter}, loss: {self.loss_count[-1]}')\n",
    "                flag = 1\n",
    "                break\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            last_loss = loss.data.cpu().numpy()\n",
    "\n",
    "        if flag == 0 and verbose:\n",
    "            print(f'Algorithm may not converge for RWN model, loss: {self.loss_count[-1]}')\n",
    "\n",
    "    def predict(self, x_new):\n",
    "        x_new = torch.FloatTensor(x_new).to(self.device)\n",
    "        return self.fnet(x_new).cpu().data.numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3ccc7b-9928-451c-b1a5-ce30e9ec36f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1, y_test1 = np.array(x_test1), np.array(y_test1)\n",
    "x_train1, y_train1 = np.array(x_train1), np.array(y_train1)\n",
    "x_train_flat1 = x_train1.reshape(x_train1.shape[0], -1)  \n",
    "x_test_flat1= x_test1.reshape(x_test1.shape[0], -1) \n",
    "y_test1=y_test1.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89370686-a6a0-46f2-a709-1208fcd336d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_below(arr, threshold):\n",
    "    return np.sum(arr < threshold)\n",
    "\n",
    "def kupiec_test(violations, total_days, significance_level):\n",
    "    expected_violations = total_days * significance_level\n",
    "    # 假设 binom_test 是一个已定义的函数，用于二项式检验\n",
    "    p_value = binomtest(violations, total_days, significance_level).pvalue\n",
    "    return p_value\n",
    "\n",
    "def target_function(dropout, hs, n_iter, lr, bs, tol, tau, num_layers,n_estimators,min_samples_split,min_samples_leaf,max_depth):\n",
    "    quantile = 0.1\n",
    "    \n",
    "    # 准备数据（这里你需要确保 x_train1, y_train1, x_test1, y_test1 是全局可访问的或作为参数传入）\n",
    "    rf = RandomForestQuantileRegressor(n_estimators=int(n_estimators)\n",
    "                                       ,min_samples_split=int(min_samples_split)\n",
    "                                       ,min_samples_leaf=int(min_samples_leaf)\n",
    "                                      ,max_depth=int(max_depth))\n",
    "                                    \n",
    "    rf.fit(x_train_flat1, y_train1)\n",
    "    mrfw, mrfwn = get_rfweight3(rf, x_train_flat1)\n",
    "    \n",
    "    # 设置 RWN3 模型的参数\n",
    "    model_rwn = RWN3(num_layers=int(num_layers), dropout=dropout, hs=int(hs), device=\"cuda\", quantile=quantile)\n",
    "    model_rwn.fit(x_train1, y_train1, mrfw, tau=tau, d=False, bs=int(bs), n_iter=int(n_iter), lr=float(lr), tol=float(tol), verbose=False)\n",
    "    \n",
    "    # 预测结果\n",
    "    y_pred1 = model_rwn.predict(x_test1)\n",
    "    y_pred1 = y_pred1.reshape(-1, 1)  # 确保 y_pred1 是列向量\n",
    "    \n",
    "    violations = count_below(y_test1, y_pred1)\n",
    "    total_days = y_test1.shape[0]\n",
    "    \n",
    "    # 计算距离\n",
    "    distance = np.abs((violations / total_days) - quantile)\n",
    "    p_value= kupiec_test(violations, total_days, quantile)\n",
    "    \n",
    "    # 输出检验结果\n",
    "    if p_value > quantile:\n",
    "        print(\"通过了kupiec检验\")\n",
    "    else:\n",
    "        print(\"没有通过kupiec检验\")\n",
    "    \n",
    "    print(f\"Iteration p-value: {p_value}\")  # 打印每次迭代的 p 值\n",
    "    \n",
    "    # 返回 -distance 作为优化目标（因为 BayesianOptimization 默认寻找最大值）\n",
    "    return -distance\n",
    "\n",
    "# 更新超参数的搜索空间，删除 quantile\n",
    "pbounds = {\n",
    "    'dropout': (0.0, 0.5),\n",
    "    'hs': (4, 128),\n",
    "    'n_iter': (500, 2000),\n",
    "    'lr': (1e-4, 1e-1),\n",
    "    'bs': (4, 256),\n",
    "    'tol': (1e-6, 1e-4),\n",
    "    'tau': (0.0, 1.0),\n",
    "    'num_layers': (1, 4),\n",
    "    'n_estimators':(50,200),\n",
    "    'min_samples_leaf':(1,15),\n",
    "    'min_samples_split':(2,20),\n",
    "    'max_depth':(5,30)\n",
    "}\n",
    "\n",
    "# 创建贝叶斯优化器对象\n",
    "optimizer = BayesianOptimization(\n",
    "    f=target_function,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# 运行贝叶斯优化\n",
    "optimizer.maximize(init_points=30, n_iter=500)\n",
    "best_params = optimizer.max['params']\n",
    "quantile = 0.1  # 保持与优化时一致\n",
    "\n",
    "# 输出最佳参数和对应的损失\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227d7e4a-dd64-4166-b558-0a939c1b1fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = x_rolling.shape[0]        \n",
    "train_end = int(total_samples * 0.8)  \n",
    "test_end = int(total_samples * 0.9)    \n",
    "val_start = test_end                   \n",
    "val_end = total_samples - 1           \n",
    "window_size=30\n",
    "# 获取贝叶斯优化后的最佳参数\n",
    "best_params = optimizer.max['params']\n",
    "\n",
    "# 初始化预测结果容器\n",
    "predictions = []\n",
    "\n",
    "# 滚动预测验证集\n",
    "for current_idx in range(val_start, val_end + 1):\n",
    "    # 动态训练集: 包含历史所有数据\n",
    "    x_train_current = x_rolling[:current_idx]      \n",
    "    y_train_current = y_rolling[:current_idx]      \n",
    "    x_train_flat = x_train_current.reshape(-1, window_size * 5)\n",
    "    \n",
    "    rf = RandomForestQuantileRegressor(\n",
    "        n_estimators=int(best_params['n_estimators']),\n",
    "        min_samples_split=int(best_params['min_samples_split']),\n",
    "        min_samples_leaf=int(best_params['min_samples_leaf']),\n",
    "        max_depth=int(best_params['max_depth'])\n",
    "    )\n",
    "    rf.fit(x_train_flat, y_train_current)\n",
    "    mrfw, mrfwn = get_rfweight3(rf, x_train_flat)\n",
    "    \n",
    "    # --- RWN3模型训练 ---\n",
    "    model_rwn = RWN3(\n",
    "        num_layers=int(best_params['num_layers']),\n",
    "        dropout=best_params['dropout'],\n",
    "        hs=int(best_params['hs']),\n",
    "        device=\"cuda\",\n",
    "        quantile=0.1\n",
    "    )\n",
    "    model_rwn.fit(\n",
    "        x_train_current,\n",
    "        y_train_current,\n",
    "        mrfw,\n",
    "        tau=best_params['tau'],\n",
    "        d=False,\n",
    "        bs=int(best_params['bs']),\n",
    "        n_iter=int(best_params['n_iter']),\n",
    "        lr=best_params['lr'],\n",
    "        tol=best_params['tol'],\n",
    "        verbose=False\n",
    "    )\n",
    "    x_next = x_rolling[current_idx].reshape(1,30,5) \n",
    "    y_pred = model_rwn.predict(x_next)\n",
    "    print(y_pred)\n",
    "    predictions.append(y_pred[0])\n",
    "\n",
    "# 转换为numpy数组\n",
    "predictions = np.array(predictions)\n",
    "print(f\"预测完成，验证集预测结果形状: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82036364-8a46-4c78-aacd-4973a6fb7130",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.reshape(-1, 1)  # 确保 y_pred1 是列向量\n",
    "y_pred1 = y_pred1.reshape(-1, 1) \n",
    "violations1 = count_below(y_pred1, predictions)\n",
    "total_days1 = y_pred1.shape[0]\n",
    "quantile=0.1\n",
    "distance1 = np.abs((violations1 / total_days1) - quantile)\n",
    "p_value1= kupiec_test(violations1, total_days1, quantile)   \n",
    "    # 输出检验结果\n",
    "if p_value1 > quantile:\n",
    "    print(\"通过了kupiec检验\")\n",
    "else:\n",
    "    print(\"没有通过kupiec检验\")\n",
    "print(p_value1)\n",
    "print(distance1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RWN",
   "language": "python",
   "name": "rwn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
